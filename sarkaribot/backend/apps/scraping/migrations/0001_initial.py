# Generated by Django 5.2.4 on 2025-08-01 11:05

import django.db.models.deletion
import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('jobs', '0001_initial'),
        ('sources', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='ProxyConfiguration',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('created_at', models.DateTimeField(auto_now_add=True, help_text='Timestamp when the record was created')),
                ('updated_at', models.DateTimeField(auto_now=True, help_text='Timestamp when the record was last updated')),
                ('host', models.CharField(help_text='Proxy server hostname or IP', max_length=255)),
                ('port', models.PositiveIntegerField(help_text='Proxy server port')),
                ('proxy_type', models.CharField(choices=[('http', 'HTTP'), ('https', 'HTTPS'), ('socks4', 'SOCKS4'), ('socks5', 'SOCKS5')], default='http', max_length=10)),
                ('username', models.CharField(blank=True, help_text='Proxy username (if required)', max_length=100)),
                ('password', models.CharField(blank=True, help_text='Proxy password (if required)', max_length=100)),
                ('status', models.CharField(choices=[('active', 'Active'), ('disabled', 'Disabled'), ('blocked', 'Blocked'), ('testing', 'Testing')], default='testing', max_length=20)),
                ('last_tested', models.DateTimeField(blank=True, help_text='Last time this proxy was tested', null=True)),
                ('success_rate', models.FloatField(default=0.0, help_text='Success rate percentage')),
                ('average_response_time', models.FloatField(default=0.0, help_text='Average response time in seconds')),
                ('requests_made', models.PositiveIntegerField(default=0, help_text='Total requests made through this proxy')),
                ('successful_requests', models.PositiveIntegerField(default=0, help_text='Successful requests')),
                ('failed_requests', models.PositiveIntegerField(default=0, help_text='Failed requests')),
            ],
            options={
                'verbose_name': 'Proxy Configuration',
                'verbose_name_plural': 'Proxy Configurations',
                'ordering': ['-success_rate', 'average_response_time'],
                'indexes': [models.Index(fields=['status'], name='scraping_pr_status_621395_idx'), models.Index(fields=['success_rate'], name='scraping_pr_success_958474_idx')],
                'unique_together': {('host', 'port')},
            },
        ),
        migrations.CreateModel(
            name='ScrapeLog',
            fields=[
                ('created_at', models.DateTimeField(auto_now_add=True, help_text='Timestamp when the record was created')),
                ('updated_at', models.DateTimeField(auto_now=True, help_text='Timestamp when the record was last updated')),
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('task_id', models.CharField(blank=True, max_length=255, null=True)),
                ('started_at', models.DateTimeField(auto_now_add=True)),
                ('completed_at', models.DateTimeField(blank=True, null=True)),
                ('duration_seconds', models.DecimalField(blank=True, decimal_places=2, max_digits=10, null=True)),
                ('status', models.CharField(choices=[('running', 'Running'), ('completed', 'Completed'), ('failed', 'Failed'), ('cancelled', 'Cancelled')], default='running', max_length=20)),
                ('scraper_engine', models.CharField(blank=True, choices=[('requests', 'Requests + BeautifulSoup'), ('playwright', 'Playwright Browser'), ('scrapy', 'Scrapy Framework')], max_length=20, null=True)),
                ('config_snapshot', models.JSONField(default=dict, help_text='Configuration used for this scrape')),
                ('pages_scraped', models.PositiveIntegerField(default=0)),
                ('requests_made', models.PositiveIntegerField(default=0)),
                ('average_response_time', models.DecimalField(blank=True, decimal_places=3, help_text='Average response time in seconds', max_digits=8, null=True)),
                ('jobs_found', models.PositiveIntegerField(default=0)),
                ('jobs_created', models.PositiveIntegerField(default=0)),
                ('jobs_updated', models.PositiveIntegerField(default=0)),
                ('jobs_skipped', models.PositiveIntegerField(default=0)),
                ('error_message', models.TextField(blank=True)),
                ('error_count', models.PositiveIntegerField(default=0)),
                ('warnings_count', models.PositiveIntegerField(default=0)),
                ('user_agent', models.CharField(blank=True, max_length=500)),
                ('ip_address', models.GenericIPAddressField(blank=True, null=True)),
                ('source', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='scrape_logs', to='sources.governmentsource')),
            ],
            options={
                'ordering': ['-started_at'],
            },
        ),
        migrations.CreateModel(
            name='ScrapedData',
            fields=[
                ('created_at', models.DateTimeField(auto_now_add=True, help_text='Timestamp when the record was created')),
                ('updated_at', models.DateTimeField(auto_now=True, help_text='Timestamp when the record was last updated')),
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('raw_data', models.JSONField(help_text='Raw scraped data as JSON')),
                ('source_url', models.URLField(max_length=500)),
                ('content_hash', models.CharField(help_text='Hash of the content for duplicate detection', max_length=32)),
                ('processing_status', models.CharField(choices=[('pending', 'Pending Processing'), ('processing', 'Being Processed'), ('processed', 'Successfully Processed'), ('skipped', 'Skipped (Duplicate)'), ('failed', 'Processing Failed')], default='pending', max_length=20)),
                ('processing_error', models.TextField(blank=True)),
                ('processed_at', models.DateTimeField(blank=True, null=True)),
                ('data_quality_score', models.DecimalField(blank=True, decimal_places=2, help_text='Quality score from 0-100 based on data completeness', max_digits=5, null=True)),
                ('field_count', models.PositiveIntegerField(default=0, help_text='Number of non-empty fields in raw data')),
                ('job_posting', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='scraped_data', to='jobs.jobposting')),
                ('source', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='scraped_data', to='sources.governmentsource')),
                ('scrape_log', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='scraped_items', to='scraping.scrapelog')),
            ],
            options={
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='ScrapingError',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('created_at', models.DateTimeField(auto_now_add=True, help_text='Timestamp when the record was created')),
                ('updated_at', models.DateTimeField(auto_now=True, help_text='Timestamp when the record was last updated')),
                ('error_type', models.CharField(choices=[('network', 'Network Error'), ('parsing', 'Parsing Error'), ('validation', 'Data Validation Error'), ('timeout', 'Timeout Error'), ('auth', 'Authentication Error'), ('rate_limit', 'Rate Limiting Error'), ('javascript', 'JavaScript Execution Error'), ('other', 'Other Error')], max_length=20)),
                ('error_message', models.TextField()),
                ('stack_trace', models.TextField(blank=True)),
                ('url', models.URLField(blank=True, max_length=500)),
                ('selector', models.CharField(blank=True, max_length=500)),
                ('raw_html', models.TextField(blank=True, help_text='HTML content at time of error')),
                ('occurred_at', models.DateTimeField(auto_now_add=True)),
                ('retry_count', models.PositiveIntegerField(default=0)),
                ('resolved', models.BooleanField(default=False)),
                ('resolution_notes', models.TextField(blank=True)),
                ('scrape_log', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='errors', to='scraping.scrapelog')),
            ],
            options={
                'ordering': ['-occurred_at'],
            },
        ),
        migrations.CreateModel(
            name='SourceStatistics',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('created_at', models.DateTimeField(auto_now_add=True, help_text='Timestamp when the record was created')),
                ('updated_at', models.DateTimeField(auto_now=True, help_text='Timestamp when the record was last updated')),
                ('date', models.DateField()),
                ('scrapes_attempted', models.PositiveIntegerField(default=0)),
                ('scrapes_successful', models.PositiveIntegerField(default=0)),
                ('scrapes_failed', models.PositiveIntegerField(default=0)),
                ('jobs_found', models.PositiveIntegerField(default=0)),
                ('jobs_created', models.PositiveIntegerField(default=0)),
                ('jobs_updated', models.PositiveIntegerField(default=0)),
                ('average_response_time', models.DecimalField(blank=True, decimal_places=3, max_digits=8, null=True)),
                ('total_pages_scraped', models.PositiveIntegerField(default=0)),
                ('average_quality_score', models.DecimalField(blank=True, decimal_places=2, max_digits=5, null=True)),
                ('source', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='daily_statistics', to='sources.governmentsource')),
            ],
            options={
                'ordering': ['-date'],
            },
        ),
        migrations.AddIndex(
            model_name='scrapelog',
            index=models.Index(fields=['source', '-started_at'], name='scraping_sc_source__34529e_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapelog',
            index=models.Index(fields=['status', '-started_at'], name='scraping_sc_status_adfcd8_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapelog',
            index=models.Index(fields=['scraper_engine', '-started_at'], name='scraping_sc_scraper_fa68c7_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapelog',
            index=models.Index(fields=['-started_at'], name='scraping_sc_started_a3d709_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapeddata',
            index=models.Index(fields=['source', '-created_at'], name='scraping_sc_source__bcc978_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapeddata',
            index=models.Index(fields=['scrape_log', 'processing_status'], name='scraping_sc_scrape__367b8f_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapeddata',
            index=models.Index(fields=['content_hash'], name='scraping_sc_content_ea0dcd_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapeddata',
            index=models.Index(fields=['processing_status', '-created_at'], name='scraping_sc_process_f44b25_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapeddata',
            index=models.Index(fields=['-created_at'], name='scraping_sc_created_7b4e83_idx'),
        ),
        migrations.AddConstraint(
            model_name='scrapeddata',
            constraint=models.UniqueConstraint(fields=('source', 'content_hash'), name='unique_content_per_source'),
        ),
        migrations.AddIndex(
            model_name='scrapingerror',
            index=models.Index(fields=['scrape_log', '-occurred_at'], name='scraping_sc_scrape__ff35e7_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapingerror',
            index=models.Index(fields=['error_type', '-occurred_at'], name='scraping_sc_error_t_877c14_idx'),
        ),
        migrations.AddIndex(
            model_name='scrapingerror',
            index=models.Index(fields=['resolved', '-occurred_at'], name='scraping_sc_resolve_a19cec_idx'),
        ),
        migrations.AddIndex(
            model_name='sourcestatistics',
            index=models.Index(fields=['source', '-date'], name='scraping_so_source__28e97a_idx'),
        ),
        migrations.AddIndex(
            model_name='sourcestatistics',
            index=models.Index(fields=['-date'], name='scraping_so_date_cee42d_idx'),
        ),
        migrations.AddConstraint(
            model_name='sourcestatistics',
            constraint=models.UniqueConstraint(fields=('source', 'date'), name='unique_source_date_stats'),
        ),
    ]
